// Copyright 2023 Cerebras Systems.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Not a complete program; the top-level source file is layout.csl.
param memcpy_params: comptime_struct;

param size: i16;

// Task IDs
param main_task_id: local_task_id;

// memcpy module reserves input queue 0 and output queue 0
const sys_mod = @import_module( "<memcpy/memcpy>", memcpy_params);

export const A = @constants([size, size]f16, 42.0);
const B = [size]i16{10, 20, 30, 40, 50};

const math_lib = @import_module("<math>");

var sqrt_diag_A = @zeros([size]f16);
var weight = @zeros([size]f16);

var ptr_weight: [*]f16 = &weight;
var ptr_sqrt_diag_A: [*]f16 = &sqrt_diag_A;

// The loop structure is implicitly specified by the memory DSD descriptions
const dsdA = @get_dsd(mem1d_dsd, .{.tensor_access = |i|{size} -> A[i, i]});
const dsdB = @get_dsd(mem1d_dsd, .{.tensor_access = |i|{size} -> B[i]});

const dsd_sqrt_diag_A = @get_dsd(mem1d_dsd, .{.tensor_access = |i|{size} -> sqrt_diag_A[i]});
const dsd_weight = @get_dsd(mem1d_dsd, .{.tensor_access = |i|{size} -> weight[i]});

export var sum : i16 = 0;

fn transformation(value : f16, coeff1 : f16, coeff2 : f16, weight : f16) f16 {
  return value * (coeff1 + weight) + value * (coeff2 + weight);
}

fn reduction(value : i16, sum : *i16) i16 {
  return sum.* + value;
}

task main_task() void {
  // Compute the square-root of each element of `dsdA` and
  // send it out to `outDSD`.
  //
  // Notice how we avoid writing an explicit loop and rely
  // on the DSD description instead.
  @map(math_lib.sqrt_f16, dsdA, dsd_sqrt_diag_A);

  // Transform tensor A in-place through a custom calculation.
  @map(transformation, dsdA, 2.0, 6.0, dsd_weight, dsdA);

  // Compute the sum of all elements in tensor B.
  @map(reduction, dsdB, &sum, &sum);

  // WARNING: the user must unblock cmd color for every PE
  sys_mod.unblock_cmd_stream();
}

comptime {
  @bind_local_task(main_task, main_task_id);
}

fn f_run() void {
  @activate(main_task_id);
  // terminate when main_task() finishes
}

comptime{
  @export_symbol(ptr_weight, "weight");
  @export_symbol(ptr_sqrt_diag_A, "sqrt_diag_A");
  @export_symbol(f_run);
  @rpc(@get_data_task_id(sys_mod.LAUNCH));
}
